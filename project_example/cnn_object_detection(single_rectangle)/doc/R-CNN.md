## R-CNN

论文链接:

```
http://islab.ulsan.ac.kr/files/announcement/513/rcnn_pami.pdf
https://papers.readthedocs.io/en/latest/imagedetection/rcnn/
https://towardsdatascience.com/r-cnn-3a9beddfd55a
https://github.com/rbgirshick/rcnn
https://blog.csdn.net/zijin0802034/article/details/77685438/
```

### 7. 实现细节

#### 7.1 对象提案方法:

我们考虑接受任意大小, 长宽比例的图像矩形提案. 而卷积神经网络使用的输入图像大小为 $227 \times 227$ , 所以需要将提案图像修改到该大小. 修改的方法有两种:

**对象提案转换**

1. 将提案矩形调整为其最小正方形, 然后截取图像, 并将该图像缩放到 $227 \times 227$.
2. 用提案矩形截取图像, 对图像短边的两端填充常量使用为正方形, 然后缩放.
3. 用提案矩形截取图像, 然后直接将其 resize 成需要的大小 $227 \times 227$.

在经过对象提案转换之后, 我们还考虑在原始对象提案周围增加其他图像上下文. 上下文填充 (p) 定义为转换后的输入坐标系中原始对象提案周围的边框大小(顶部 0 个像素, 底部 16 个像素). 实验表明这样作能提升模型最终的效果.

```
这部分建议看原文, 有点莫名其妙, 而且已提案转换后的图像大小是 CNN 所要求的, 那么多出来的 padding 应该是怎么填充呢. 论文中的示例图表示的不是很明白.
```



调整图像时在其边界填充的常量取值为这部分图像的平均值, 然后在图像传入 CNN 之将, 预处理图像方法为, 将图像减去其像素的平均值. 所以填充的部分在进入 CNN 时, 其值为 0.



### 7.2 正例与负例和 softmax

有两个设计选择值的进一步讨论. 第一个是: 为什么在微调 CNN 和训练对象检测 SVM 方面对正例和负例的定义不同 ? 这了简短地回顾定义, 为了进行微调, 我们将每个对象提案映射到具有最大 IoU 重叠的 gound-truth 实例. 并将其标记为匹配 ground-truth 实例类别的正例 (如果 IoU 处于至少 0.5). 所有的其他对象提案都标记为 "背景" (即, 所有类别的负例). 相比之下, 在训练 SVM 时, 我们仅将 ground-truth boxes 作为各自类别的正面示例, 而将与该类别的所有实例重叠 IoU 小于 0.3 的实例视为负面示例. 落入灰色区域的提案 (重叠的 IoU 超过 0.3, 但不是 ground-truth 的被忽略). 

从历史上讲, 我们之所以得出这些定义, 是因为我们首先对 ImageNet 预训练的 CNN 计算出的特征进行 SVM 训练, 因此此时不考虑微调. 在该设置中, 我们发现用于训练 SVM 的特定标签定义在我们评估的选项集 (包括我们现在用于微调的设置) 内是最佳的. 当我们开始使用微调时, 我们最初使用与 SVM 训练相同的正例和负例定义. 但是, 我们发现结果比使用我们当前对正负的定义所获得的结果差得多. 

我们的假设是, 对正负定义方式的区别根本上并不重要, 而是由于微调数据有限而引起的. 我们当前的方案引入了许多 "抖动的" 示例 (那些提案的重叠度在 0.5 到 1 之间, 但没有真实性), 这使正例的数量增加了大约 30 倍. 我们推测, 在微调整个网络以避免过度拟合时需要使用这个大集合. 但是, 我们也注意到, 使用这些抖动示例可能不是最佳选择, 因为未对网络进行微调以实现精确定位. 

这就引出了第二个问题: 为什么在进行微调之后还要训练 SVM ? 只需将微调网络的最后一层 (即 21 向 softmax 回归分类器) 用作对象检测器, 会更清洁. 我们对此进行了尝试, 发现 VOC 2007 的性能从 54.2% 下降到 50.9%. 这种性能下降可能是由多种因素共同导致的, 其中包括微调中使用的正例的定义不强调精确的定位, 并且 softmax 分类器是针对随机采样的负例而非使用用于 SVM 训练的 "真负例" 子集进行训练的. 

结果表明, 微调后无需训练 SVM, 就可以获得接近相同水平的性能. 我们推测, 通过一些其他调整来微调剩余的性能差距可能会得到弥补. 如果为 true, 这将简化并加速 R-CNN 训练, 而不会降低检测性能. 







### 7.3 Bounding box 回归

我们使用一个简单的 bounding-box 回归步骤来提升定位性能. 在使用 SVM 分类器对对象提案进行分类之后, 我们使用 bounding-box 回归为检测对象预测一个新的 bounding box. 这在本质上与可变形零件模型中使用的包围盒回归相似. 两种方法之间的主要区别在于, 这里我们从 CNN 计算的特征回归, 而不是从推断 DPM 零件位置计算的几何特征回归. 

我们的训练算法的输入是一组 N 个训练对 $\{(P^{i}; G^{i})\}_{i=1, 2, \cdot \cdot \cdot, N}$, 其中 $P_{i} = (P_{x}^{i}, P_{y}^{i}, P_{w}^{i}, P_{h}^{i})$ 指定对象提案 $P^{i}$ 的 bounding box 的中心像素坐标及 width 和 height. 因此, 除非需要, 否则我们将删除上标 i . 每一个 ground-truth bounding box G (ground-truth 的含意是数据标注的真实 bounding box)以同样的方式指向 $G=(G_{x}, G_{y}, G_{w}, G_{h})$. 我们的目标是训练出一个从 bounding box P 转换映射到 ground-truth box G 的方法. 

我们将转换公式表示为 4 个公式 $d_{x}(P), d_{y}(P), d_{w}(P), d_{h}(P)$. 前两个指向一个对 bounding box P 的尺度不变的转换, 后两个点向一个对 bounding box P 的宽度高度的 log 对数转换. 通过学习这些函数, 我们可以转换输入对象提案 P 到预测 ground-truth box $\hat{G}$, 通过: 

$$\begin{aligned} \hat{G}_{x} &= P_{w}d_{x}(P) + P_{x} \\ \hat{G}_{y} &= P_{h}d_{y}(P) + P_{y} \\ \hat{G}_{w} &= P_{w}exp(d_{w}(P)) \\ \hat{G}_{h} &= P_{h}exp(d_{h}(P)) \end{aligned}$$

```tex
备注: 
1. 图像标注中指定了哪些区域包含了对象, 及对象的类别. 这些标注是此处的 G(x, y, w, h). 
2. 其中 $\phi_{5}(P)$ 表示 CNN 网络在 pool5 输出的对象提案特征, 将此特征展平, 与权重向量 w 相乘, 得到 d(P). 
```



每一个函数 $d(P) $ 被建模为提案 P 的 pool5 特征的线性函数, 用 $\phi_{5}(P)$ 表示. (隐式假设 $\phi_{5}(P)$ 依赖于图像数据). 因此, 我们有 $d(P) = w^{T}\phi_{5}(P)$, 其中 $w$ 是一个可学习的模型向量. 通过优化正则化最小二乘目标 (岭回归): 

$\begin{aligned} w = argmin \sum_{i}^{N}{(t^{i} - \hat{w}^{T}\phi_{5}(P^{i}))^{2} + \lambda||\hat{w}||^{2}} \end{aligned}$

训练对 $(P, G)$ 的回归目标 t 定义为: 

$\begin{aligned} t_{x} &= (G_{x} - P_{x}) / P_{w} \\ t_{y} &= (G_{y} - P_{y}) / P_{h} \\ t_{w} &= log(G_{w} / P_{w}) \\ t_{h} &= log(G_{h} / P_{h}) \end{aligned}$

作为标准的正则化最小二乘问题, 可以用封闭形式有效地解决它. 



在实现 bounding-box 回归的过程中我们发现两个微妙的问题. 首先是正则化很重要: 我们基于验证集设置 $\lambda = 1000$ . 第二个问题是选择要使用的训练对 $(P; G)$ 时必须要小心. 直观地讲, 如果 P 远离所有 ground-true boxes. 那么将 P 转换为 ground-true box G 是没有意义的. 使用类似 P 的样本将导致无望的学习问题. 所以我们只学习具有至少一个邻近 ground-truth box 的对象提案 P. 当 P 具有多个重叠 ground-truth box 时, 我们选择与 P 具有最大 IoU 重叠量的 ground-truth box G 且此 IoU 值还应大于一定阈值 (在验证集中我们将此 IoU 阈值设置为 0.6),  所有不符合的对象提案都会被丢弃. 我们对每个对象类别执行一次上操作, 以学习一组针对类别的 bounding-box 回归器. 

在测试时, 我们对每个提案进行评分, 并仅预测一次其新的检测窗口. 原则上, 我们可以重复此过程 (即, 对新预测的边界框重新评分, 然后从中预测新的边界框, 依此类推). 但是, 我们发现迭代并不能改善结果. 



### 7.4 数据集交叉冗余分析























