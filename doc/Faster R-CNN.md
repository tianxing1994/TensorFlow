## 更快的 R-CNN: 通过区域提议网络实现实时目标检测

Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun

<https://arxiv.org/pdf/1506.01497.pdf>



### 摘要

最新的物体检测网络依靠区域提议算法来假设物体的位置. SPPnet 和 Fast R-CNN 之类的进步, 减少了这些检测网络的运行时间, 暴露了区域提议计算的瓶颈. 在这项工作中, 我们引入了一个区域提议网络 (RPN), 该网络与检测网络共享全图像卷积特征, 从而实现几乎无损耗的区域提议. RPN 是一个完全卷积的网络, 可以同时预测每个位置的对象范围和对象得分. 对 RPN 进行了端到端的训练, 以生成高质量的区域建议, 并用于 Fast R-CNN 进行检测. 通过共享 RPN 和 Fast R-CNN 的卷积特征, 我们将 RPN 和 Fast R-CNN 进一步合并为一个网络-使用最近流行的带有 "注意力" 机制的神经网络术语, RPN 组件告诉统一网络在哪里查看. 对于非常深的 VGG-16 模型, 我们的检测系统在 GPU 上具有 5fps (包括所有步骤) 的帧频, 同时在 PASCAL VOC 2007, 2012 和 2007 上达到了最新的对象检测精度. MS COCO 数据集, 每个图像仅包含 300 个提议. 在 ILSVRC 和 COCO 2015 竞赛中, Faster R-CNN 和 RPN 是多个赛道中第一名获胜作品的基础.





### 1. 介绍

区域提议方法和基于区域的卷积神经网络 (RCNN) 的成功推动了对象检测的最新进展. 尽管基于区域的 CNN 在计算上很昂贵, 但由于在提案之间共享卷积, 因此其成本已大大降低. 最新的 Fast R-CNN, 在忽略区域提案花费的时间时, 使用非常深的网络实现了接近实时的速度. 现在, 对象提议部分是目前检测系统在测试时的计算瓶颈.

区域提议方法通常依赖于计算代价较低的特征和算法. 选择性搜索是最流行的方法之一, 它根据工程化的底层特征贪婪地合并超像素. 然而, 与高效的检测网络相比, 选择性搜索的速度要慢一个数量级, 在 CPU 实现中每张图像 2 秒. EdgeBoxes 当前提供建议质量和速度之间的最佳权衡, 每张图像 0.2 秒. 尽管如此, 区域提议步骤仍然消耗与检测网络一样多的运行时间. 可能有人注意到, 基于区域的快速 CNN 流分利用了 GPU 的优势, 而研究中使用的区域提议方法是在 CPU 上实现的, 因此这种运行时比较是不公平的. 加速提案计算的一种明显方法是在 GPU 上重新实现. 这可能是一种有较的工程解决方案, 但是重新实现会忽略下游检测网络, 因此会错过共享计算的重要机会.

在本文中, 我们展示一个算法的变化 (使用深度卷积神经网络计算提议) 以得到一种优雅而有效的解决方案, 考虑到检测网络的计算, 提议计算几乎是无消耗的. 为此, 我们介绍与最新的对象检测网络共享卷积层的新颖的区域提议网络 (RPN). 通过在测试时共享卷积, 计算提议的边际成本很小 (例如, 每张图片 10 毫秒). 我们的观察结果是, 基于区域的检测器 (如 Fast RCNN) 使用的卷积特征图也可用于生成区域提议. 在这些卷积特征之上, 我们通过加少许卷积层来构建 RPN, 这些卷积层同时回归规则网格上每个位置的区域边界和对象得分. 因此, RPN 是一种全卷积网络 (FCN), 可以专门针对检测提议的任务进行端到端训练.

RPN 旨在有效地预测具有各种比例和长宽比的区域提案. 与使用图像金字塔或滤镜金字塔的流行方法相反, 我们引入了新颖的 "锚" 盒, 它们可以在多个比例和长宽比下用作参考. 我们的方案可以看作是回归参考的金字塔, 它避免了枚举具有多个比例或长宽比的图像或过滤器. 当使用单比例尺图像进行训练和测试时, 该模型表现良好, 从而提高了运行速度.

为了将 RPN 和快速 R-CNN 对象检测网络统一起来, 我们提出了一种训练方案, 该方案在对区域提议任务进行微调与对对象检测进行微调之间交替, 同时保持提议不变. 该方案可以快速收敛, 并生成具有两个任务之间共享的卷积特征的统一网络.

我们在 PASCAL VOC 检测基准上全面评估了我们的方法, 其中具有 Fast R-CNN 的 RPN 产生的检测精度要优于具有Fask R-CNN 的选择性搜索的强基线. 与此同时, 我们的方法在测试时几平免除了 "选择性搜索" 的所有计算负担, 区域提议的有效运行时间仅为 10 毫秒. 使用高代价的深层模型, 我们的检测试法在 GPU 上的帧速率仍然为 5fps (包括所有步骤), 因此在速度和准确性方面都是实用的对象检测系统. 我们还报告了 MS COCO 数据集的结果, 并使用 COCO 数据研究了 PASCAL VOC 的改进. 代码在 https://github.com/shaoqingren/faster_rcnn (MATLAB) 和 https://github.com/rbgirshick/py-faster-rcnn (Python).

该手稿的初步版本先前已发布. 从那时起, RPN 和 Faster R-CNN 的框架就被采用并推广到其他方法, 例如 3D 对象检测, 基于零件的检测, 实例分割和图像字幕. 我们的快速有效的物体检测系统也已建立在商业系统中, 例如, Pinterests, 据报道用户参与度有所提高. 在 ILSVRC 和 COCO 2015 竞赛中, Faster R-CNN 和 RPN 是 ImageNet 检测, ImageNet 本地化, COCO 检测和 COCO 分割中几个第一名的基础. RPN 完全学会了根据数据提议区域, 因此可以轻松地从更深, 更具高现力的特征 (如 101 层的 residual nets. ) 中受益. 在这些比赛中, 其他一些领先的参赛者也使用了 Faster R-CNN 和 RPN. 这些结果表明, 我们的方法不仅是一种实用的高性价比解决方案, 而且还是提高物体检测精度的有效途径.


### 2. 相关工作

**对象提议**. 这里有大量的关于对象提议方法的文献. 可以找到对象提议方法的全面调查和比较. 广泛使用的对象建议方法包括基于超像素分组的方法 (例如, 选择性搜索, CPMC, MCG) 和基于滑动窗口的方法 (例如, 窗口中的对象, EdgeBoxes). 饿死用对象提议方法作为独立于检测器的外部模块 (例如, 选择性搜索对象检测器, RCNN, Fast-RCNN).


**用于对象检测的深度网络**. R-CNN 方法训练 CNN 端到端网络分类提议区域为某对象类别或是背景. 其再多地表现为一个分类器, 它不会预测对象的边界 (能对边界框回归进行优化除外). 它的精度依赖于区域提案模块. 几篇论文提出了使用深度网络预测对象边界框的方法. 在 OverFeat 方法中, 通过训练一个全连接层来预测单个目标定位任务的 box 坐标. 全连接层接着又转入一个卷积层, 用于检测对象分类. MultiBox 方法, 从网络中生成区域提议, 该网络的最后一个完全连接的层同时预测多个与类无关的盒子, 从而概括了 OverFeat 的 "singlebox" 方法. 这些类别未知的 boxes 被用作 R-CNN 的区域提议. 与我们的全卷积方案相比, MultiBox 区域提议网络适用于单个图片截取或多个大图片截取如 (224X224). MultiBox 不在提议和检测网络之间共享特征. 我们稍后将在我们的方法中更深入地讨论 OverFeat 和 MultiBox. 在我们工作的同时, 开发了 DeepMask 方法以学习细分提案.


卷积和共享计算已吸引了越来越多的关注, 以进行有效而准确的视觉识别. OverFeat 论文从图像金字塔计算卷积特征, 以进行分类, 定位和检测. 共享卷积特征图上的自适应大小池(SPP) 被开发用于有效的基于区域的对象检测, 和语义分割. Fast R-CNN 可以对共读取卷积特征进行端到端检测器训练, 并显示出令人信服的准确性和速度.

### 3. Faster R-CNN

我们的物体检测系统称为 Faster R-CNN, 它由两个模块组成. 第一个模块是提出区域的深层全卷积网络, 第二个模块是使用提出的区域在 Fast R-CNN 检测器上处理. 整个系统是用于对象检测的单个统一网络. RPN 模块使用最近流行的带有 "注意力" 机制的神经网络术语, 可以告诉 Fast R-CNN 模块在哪里查看. 在第 3.1 节中, 我们介绍用于区域提议的网络的设计和属性.



#### 3.1 区域提议网络

区域提议网络 (RPN) 接收 (任意大小的) 图像作为输入, 并输出一组矩形的目标提议, 每个目标提议都有一个客观得分. 我们使用全卷积网络对此过程进行建模, 这将在本节中进行描述. 因为我们最终目标是与 Fast R-CNN 对象检测网络共享计算, 所以我们假设两个网络共享一组共同的卷积层. 在我们的实验中, 我们研究了 Zeiler 和 Fergus 模型(ZF), 其具有 5 个可共享的卷积层, 而 Simonyan 和 Zisserman 模块 (VGG-16) 具有 13 个可共享的卷积层.

为了生成区域提议, 我们在最后共享的卷积层输出的卷积特征图上滑动小型网络. 每个滑动窗口都映射到一个较低维的特征 (ZF 为 256-d, VGG 为 512-d, 返回是 Relu). 这个特征被馈入两个同级的全连连接层- 框架归层(reg) 和框分类层 (cls). 在本文中, 我们使用 n=3, 注意, 输入图像上的有效接收场很大 (ZF 和 VGG 分别为 171 和 228 像素). 在图 3 的单个位置 (左) 显示了此微型网络. 注意, 由于微型网络以滑动窗口的方式运行, 因此完全连接的层将在所有空间位置上共享. 该体系结构自然是由 $n \times n$ 卷积层和两个同级 $1 \times 1$ 卷积层 (分别用于 reg 和 cls) 实现的.



#### 3.1.1 锚点

在每个滑动窗口位置, 我们同时预测多个区域提议, 其中每个位置的最大可能提议数目表示为 k. 因此, reg 层有 4k 个输出, 对 k 个盒子的坐标进行编码, 而 cls 层则输出 2k 个得分, 这些得分估计每个提议的目标或非目标概率. 相对于 k 个参考框 (称为锚点), 对 k 个建议进行了参数化. 锚点位于相关滑动窗口的中心, 并与比例和宽高比相关联. 默认情况下, 我们使用 3 个比例和 3 个长宽比, 在每个滑动位置产生 k=9 个锚点. 对于大小为 $W \times H$ (通常为 2400) 的卷积特征图, 总共有 $WHk$ 个锚点.

**解释不变锚点**

我们的方法的一个重要特性是, 在锚点和计算机对于锚点的提案的函数方面, 它都是平移不变的. 如果一个人解释了图像中的一个对象, 则该提议应进行解释, 并且相同的函数应能够在任一位置预测出此提议. 此平移不变属性由我们的方法 5 保证. 相比之下, MultiBox 方法使用 k-Means 生成 800 个锚点, 这些锚点不是平移不变的. 因此, MultiBox 不保证解释对象时会生成相同的提议.

平移不变属性还减小了模型的大小. MultiBox 具有 $(4+1) \times 800$ 维全连接输出层, 而在 k=9 个锚点的情况下, 我们的方法具有一个 $(4+2) \times 9$ 维卷积输出层. 结果, 我们的输出层有 $2.8 \times 10^{4}$ 个参数 (对于 VGG-16 $512 \times (4 + 2) \times 9$), 比 MultiBox 的输出层参数少两个数量级 $6.1 \times 10 ^{6}$ ($1536 \times (4+1) \times 800$ 对于 GoogleNet). 如果考虑到特征映射层, 我们的提议层参数仍然比 MultiBox6 少一个数量级的参数. 我们希望我们的方法在较小的数据库 (如 PASCAL VOC) 上过拟合的风险较小.

**多尺度锚点作为回归参考**

我们的锚点设计提出了一种解决多种比例(和长宽比)的新颖方案. 如图 1 所示, 有两种流行的多尺度预测方法. 第一种是基于图像特征金字塔. 在 DPM 和 CNN 为基础的方法中. 图片被 resized 到多种尺度, 并分别计算特征图. 这种方法经常被使用, 但是很消耗时间. 第二种方法是在特征图上使用多种尺度的滑动窗口. 例如 DPM 中, 模型的不同长宽比是通过不同的滤波尺度分开训练的. 如果这种方法被认定为多尺度, 可以将其看作是 "滤波金字塔". 第二种方法通常和第一种方法结合使用.

相比之后, 我们的基于锚点的方法是基于锚点金字塔构建的, 这种方法更具成本效益. 我们的方法参考多个比例和长宽比的锚框进行分类和回归. 它仅依赖于单一比例的图像和特征图, 并使用单一大小的滤镜(在特征图上滑动窗口). 我们通过实验证明了该方案对解决多种规模和规模的景响. 由于基于锚的这种多尺度设计, 我们可以简单地使用在单尺度图像上计算出的卷积特征, 就像 Fast R-CNN 检测器所做的一样. 多尺度锚点的设计是共享特征而无需花费额外成本解决尺度的关键组成部分.

#### 3.1.2 损失函数

为了训练 RPNs, 我们设计了一个二分类标签为每个锚点 (是或不是一个对象). 如果 (1) 一个锚点是任意 ground-truth box 所具有的 IoU 重叠值的最大值, 我们就给他分配一个正的标签, 或者 (2) 如果这个锚点的 IoU 值超过 0.7. 注意, 单个的 ground-truth box 可能给多个锚点分配正的标签. 通常, 第二种情况就足以确定正例, 但我们仍然决定采用第一种方法, 因为在极少数情况下, 第二种情况可能找不到正样本. 我们给非正的锚点分配负标签, 如果它的 IoU 率对于任意的 ground-truth boxes 都低于 0.3. 既不属于正例, 出不属于负例的样本不参与训练.

利用这些定义, 我们将 Fast R-CNN 中多任务损失之后最小化目标函数, 我们的损失函数定义如下:

$$\begin{aligned} L(\{p_{i}\}, \{t_{i}\}) = \frac{1}{N_{cls}}\sum_{i}{L_{cls}(p_{i}, p_{i}^{*})} + \lambda \frac{1}{N_{reg}}\sum_{i}{p_{i}^{*}L_{reg}({t_{i}, t_{i}^{*}})} \end{aligned}$$

此处,

* $i$ 是每一小批次中锚点的索引,
* $p_{i}$ 是一个锚点被预测为是一个对象的概率值.
* gorund-truth 标签 $p_{i}^{*}$ 是 1, 如果锚点为正例, 为 0, 如果锚点为负例.
* $t_{i}$ 是一个向量, 代表了预测的 bounding-box 的 4 个参数化坐标.
* $t_{i}^{*}$ 是 ground-truth box 的 4 个参数化坐标的真实值.
* $L_{cls}$ 分类损失是两个类别之间的 log 对数损失.

对于回归损失, 我们使用 $L_{reg}(t_{i}, t_{i}^{*}) = R(t_{i} - t_{i}^{*})$ 其中 R 是键壮损失函数 (平滑 $L_{1}$). 定义在 [2] 中. 式 $p_{i}^{*}L_{reg}$ 表示回归损失只在中样本中进行计算, 在负样本中不参与计算. cls 和 reg 层的输出分别由 fpig 和 ftig 组成.

这两项通过 $N_{cls}$ 和 $N_{reg}$ 进行归一化, 并通过平衡参数 $\lambda$ 进行加权. 在我们当前的实现中, 等式中的 cls 项, 在小批次 ($N_{cls} = 256$) 下行正则化, reg 回归项通过锚点位置的数量进行正则化 (如: $N_{reg} - 2400$). 默认情况下, 我们设置 $\lambda = 10$, 这使得 cls 和 reg 项的权重接近相等. 我们通过实验表明结果对于在较大范围内的 $\lambda$ 不敏感. 我们还注意到, 上面的标准化不是必须的, 可以简化.


对于 bounding box 回归, 我们采用 4 个参数化坐标:

$$\begin{aligned} t_{x} &= (x - x_{a}) / w_{a}, t_{y} = (y-y_{a}) / h_{a}, \\ t_{w} &= log(w/w_{a}), t_{h} = log(h / h_{a}), \\ t_{x}^{*} &= (x^{*} - x_{a})/w_{a}, t_{y}^{*} = (y^{*} - y_{a})/h_{a}, \\ t_{w}^{*} &= log(w^{*}/w_{a}), t_{h}^{*} = log(h_{*}/h_{a}) \end{aligned}$$

其中, $x, y, w, h$ 别分表示 box 的中心坐标, 和它的宽度和高度. 变量 $x, x_{a} x^{*}$ 表示预测的 box, 锚点 box, 和真实的 ground-truth box. ($y, w, h$ 也是一样). 这可以看作是从一个锚点 box 向真实 box 进行回归.

然而, 我们的方法通过不同于以前基于 RoI 的方法, 来实现包围盒回归. 对任意大小的 RoI 合并的特征执行边界框回归, 并且回归权重由所有区域大小共享. 在我们的公式中, 用于回归的特征在特征图上具有相同的空间大小 ($3 \times 3$). 为了说明变化的大小, 学习了一组 k 个边界框回归器. 每个回归器负责一个比例和一个长宽比, 而 k 个回归器不共享权重. 这样, 由于锚点的设计, 即使特征具有固定的大小/比例, 仍然可以预测各种大小的盒子.



#### 3.1.3 训练 RPNs

可以通过反向传播和随机梯度下降 (SGD) 端到端训练 RPN. 我们遵循 "以图像为中心" 的采样策略来训练该网络. 每一个小批次处理均来自包含多个正负示例锚点的单个图像. 可以针对所有锚点的损失函数进行优化. 但这会偏向负面样本, 因为它们占主导地位. 取而代之的是, 我们在图像中随机采样 256 个锚, 以计算微型批次的损失函数, 其中正采样和负锚的采样比例最高为 1:1. 如果图像中的正样本少于 128 个, 则用负样本填充小批量.

我们通过从零均值高斯分布中初始化权重 (标准偏差为 0.01) 来随机初始化所有新层. 所有其他层 (即共享卷积层) 都通过预先训练 ImageNet 分类模型来初始化, 这是标准做法. 我们调整 ZF 网络的所有层, 并转换 conv3_1 以及 VGG 网络以节省内存. 在 PASCAL VOC 数据集上, 我们对 6 万个小批次使用 0.001 的学习率, 对接下来的 2 万个小批量使用 0.0001 的学习率. 我们使用 0.9 的动量和 0.0005 的权重衰减. 我们的实现使用 Caffe.


#### 3.2 RPN 和 Fast R-CNN 的共享特征.

到目前为止, 我们已经描述了如何为生成区域提议而训练网络, 而没有考虑将这些提议的基于区域的对象检测 CNN. 我们采用 Fast R-CNN 检测网络. 接下来, 我们将描述学习具有 RPN 和 Fast R-CNN 并且有共享卷积层的统一网络的算法.

经过独立训练的 RPN 和 Fast R-CNN 都将以不同的方式修改其卷积层. 因此, 我们需要开发一种技术, 该技术允许在两个网络之间共享卷积层, 而不是学习两个单独的网络. 我们讨论了三种共享功能的网络训练方法;

1. 交替训练. 在此解决方案中, 我们首先训练 RPN, 然后使用这些建议来训练 Fast R-CNN. 然后, 使用由 Fast R-CNN 调整的网络初始化 RPN, 然后重复此过程. 这是本文所有实验中使用的解决方案.

2. 大约联合训练. 在这解决方案中, RPN 和 Fast R-CNN 在训练时被合并为一个网络, 在每个 SGD 迭代中, 前向生成的区域提议在训练 Fast R-CNN 检测器时就像固定的, 预先计算的提议一样对待. 反向传播照常进行, 其中对于共享层, 来自 RPN 损耗和快速 R-CNN 损耗的反向传播信号被组合在一起. 该解决方案易于实现. 但是此解决方案忽略了导数 w.r.t. 提案框的坐标也是网格响应, 因此是近似值. 在我们的实验中, 我们凭经验发现此求解器产生的结果接近, 但与交替训练相比, 训练时间减少了约 25-50%. 此求解器包含在我们发布的 Python 代码中.


3. 非近似的联合训练. 如上所述, RPN 预测的边界框也是输入的函数. 快速 R-CNN 中的 RoI 合并层[2] 接受卷积特征, 并接受预测的边界框作为输入, 因此, 理论上有效的反向传播求解器也应包含梯度w.r.t. 框坐标. 这些梯度在上面的近似联合训练中被忽略. 在一个非近似的联合训练解决方案中, 我们需要一个w.r.t. 框坐标. 这是一个不平凡的问题, 可以通过[15]中开发的 "RoI翘曲" 层来提供解决方案, 这超出了本文的范围.



**四步交替训练**