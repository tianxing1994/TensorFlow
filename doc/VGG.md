
##   VGG 非常深的卷积网积用于大范围图像识别
https://arxiv.org/pdf/1409.1556.pdf



### 摘要

在此我们研究卷积网络在大范围图像识别中的深度对精度的影响. 我们的主要贡献是使用具有非常小 (3×3) 卷积核的体系结构对深度不断增加的网络进行全面评估. 其表明通过将深度推至 16-49 个权重层可以实现对现有技术配置的重大改进. 这些发现是我们提交 2014 年 ImageNet 挑战赛的基础. 其中, 我们的团队分别在定位和分类问题上获得了第一和第二名. 我们还表明, 我们的表示法可以很好地推广到其他数据集. 他们获得了最先进的结果. 我们已经公开提供了两个性能最佳的 ConvNet 模型, 以促进对在计算机视觉中使用深层视觉表示的进一步研究.


### 介绍
卷积网络 (ConvNet) 最近在大范围图像和视频识别中取得了巨大成功. 这得益于大型公共图像库 (如 ImageNet) 和高性能计算系统 (如 GPU 或大规模分布式集群). 特别是, ImageNet 大规模视觉识别挑战赛 (ILSVRC) 在深度视觉识别架构的发展中发挥了重要作用, 它已成为几代大型尺度图像分类系统, 从高维浅特征编码到深层 ConvNets.
随着 ConvNets 在计算机视觉领域中越来越成为一种商品, 人们进行了许多尝试来改进 Krizhevsky 等人的原始体系结构. 以达到更好的准确性. 例如, 向 ILSVRC-2013 提交的最佳表现利用了**较小的接收窗口大小**和**较小的第一卷积层跨度**. 另一项改进涉及在整个图像上和多个尺度上密集地训练和测试网络. 在本文中, 我们讨论了 ConvNet 体系结构设计的另一个重要方面 - 深度. 为此, 我们修复了体系结构的其他参数, 并通过添加更多的卷积层来稳定地增加了网络的深度, 这是可行的, 因为所有层都使用了非常小的 (3×3) 卷积核.
因此, 我们提出了更为精确的 ConvNet 架构, 该架构不仅在 ILSVRC 分类和定位任务上达到了最先进的准确性, 而且还适用于其他图像识别数据集, 即使在这些数据集下, 它们也可以获得出色的性能, 当用作相对简单的管道的一部分时 (例如, 通过线性 SVM 分类的深层特征而无需微调). 我们发布了两个性能最佳的模型, 以促进进一步的研究.
本文的其余部分安排如下:

* 第 2 部分, 我们描述我们的 ConvNet 的配置.
* 第 3 部分, 介绍图像分类训练和评估的细节.
* 第 4 部分, 比较 ILSVRC 分类任务上的配置.

* 第 5 部分, 总结.

为了完整起见, 我们还在附录 A 中描述和评估我们的 ILSVRC-2014 对象本地化系统, 并在附录 B 中讨论了非常深入的功能推广到其他数据集的方法. 最后, 附录 C 包含了主要论文修订清单.

### 2. ConvNet 配置
为了在公平的环境下衡量不断增加的 ConvNet 深度带来的改进, 我们的所有 ConvNet 层配置均采用相同的原理设计, 并受到 Ciresan 等人的启发. 在本节中, (2.1 节) 我们首先描述 ConvNet 配置的通用布局, 然后 (2.2 节) 详细介绍评估中使用的特定配置. 然后 (2.3 节) 讨论我们的设计选择, 并将其与现有技术进行比较.

#### 2.1 结构
训练时的输入图像大小固定为 224×224 的 RGB 图像. 唯一的预处理是从每个像素减去 RGB 图像的均值 (均值从训练集中计算得出). 图像通过一叠卷积 (conv.) 层传递, 在这里我们使用具有很小接收域的卷积核: 3×3 (这是捕获左/右, 上/下, 中心的信息的最小尺寸). 我们也使用了 1×1 的卷积核, 这可以看作是对输入通道的线性变换 (其后跟随着非线性变换). 卷积的步幅固定为 1 个像素. 同时为保持卷积前后图像的空间分辨率不变, 对于 3×3 的卷积, 则图像边界填充 1 个像素. 空间池化由 5 个最大池化层执行, 它们跟随在某些 conv 卷积层的后面. 最大值池化采用 2×2 的窗口, 步幅为 2.

一叠卷积层 (卷积层不同结构处的深度不一样) 之后跟随着 3 个全链接层 (FC): 前两个分别具有 4096 个通道. 第三个执行 ILSVRC 分类的 1000 个分类目标, 因此包含 1000 个通道. 最后一层是 soft-max 层. 在所有网络中, 完全连接的层 (FC) 的配置都是相同的 (第一个全连接层采用 7×7 的卷积实现全连接, 后两个采用 1×1 的卷积实现全连接).
所有隐藏层都配备了非线性整流 (ReLU). 我们提示, 我们的网络 (除了一处) 均不包含本地响应规范化 (LRN): 这将在第 4 部分说明, 这种规范化不能改善 ILSVRC 数据集的性能, 且会增加内存消耗和计算时间.


#### 2.2 配置
ConvNet 的配置展示在表 1 中, 后面我们将用它们的字称 (A-E) 来指代它们. 所要配置都遵循 2.1 节中介绍的通用设计. 仅在深度上有所不同: 网络 A 中的 11 个权重层 (8 个卷积层和 3 个 FC 层) 到网络 E 中的 19 个权重层 (16 个卷积层和 3 个 FC 层). 卷积层的通道数从第一层的 64 开始, 每一次最大值池化就增加为原来的 2 倍, 直到达到 512 个为止. 

在表 2 中我们报告了每种配置的参数数量. 尽管深度较大, 但我们的网络并不比同类型具有较大卷积核尺寸的网络的参数更多.

#### 2.3 讨论
我们的 ConvNet 配配与 ILSVRC-2012 和 ILSVRC-2013 的顶级作品中使用的配置完全不同. 与其在第一卷积层中使用核大的接收场 (如: 11×11, 步幅为 4, 或者是 7×7, 步幅为 2), 我们的整个网络中使用非常小的 3×3 卷积核, 其与图像的每个像素进行卷积 (步幅为 1). 很容易看出, 两层 3×3 的卷积层具有 5×5 的感受野. 三层则具有 7×7 的感受野. 那么使用 3 层 3×3 的卷积核, 比单个 7×7 的卷积核有什么好处呢.

三层卷积, 跟随了三次 ReLU 非线性整流, 这使得决策函数具有更好的区分性.2. 减少了参数的数量. 如输入和输出的张量都具有相同的通道数 C, 则 3 个 3×3 的卷积层, 参数数量为: $3(3^{2}C^{2}) = 27C^{2}$ ; 同样的单个 7×7 的卷积层则具有 $7^{2} C^{2} = 49C^{2}$ 个参数. 增加了 $81%$ 以上.

这可以看作是对 7×7 卷积强加了正则化. 迫使它们通过 3×3 的滤波器进行分解 (在其间注入非线性整流).
合并 1×1 卷积层, 是增加决策函数的非线性度而不影响 conv 卷积感受野的一种方法. 即使 1×1 的卷积实际上是在相同维度的空间上的线性投影 (输入和输出通道的数量相同), 但整流函数会引入额外的非线性. 应该注意的是, 最近在 Lin 等人的 "Network in Network" 架构中使用了 1×1 卷积层.

Ciresan 等人先前已使用小型卷积核. (2011年), 但它们的网络深度远小于我们的网络, 并且它们没有在大型 ILSVRC 数据集上进行评估. 将深层 ConvNets (11 个权重层) 应用于街道编号识别任务, 并表明增加的深度导致更好的性能.
GoogLeNet (Szegedy等人, 2014) 是 ILSVRC-2014 分类任务中表现最好的一项, 它的开发与我们的工作无关, 但是类似, 它基于非常深的 ConvNets (22 个权重层) 和小的卷积过滤器 (除了 3×3, 它们还使用 1×1 和 5×5 卷积). 但是, 它们的网络拓扑比我们的网络拓扑更复杂, 并且在第一层中更加积极地降低了特征图的空间分辨率, 从而减少了计算量. 4.5 节所示, 我们的模型优于 Szegedy 等人的模型. (2014) 在单网络分类准确性方面.



### 分类框架
在上一节中, 我们介绍了网络配置的详细信息. 在本节中, 我们描述分类 ConvNet 训练和评估的详细信息.



#### 3.1 训练

ConvNet 训练的过程通常遵循 Krizhevsky 等人的观点 (除了从多尺度采样训练图像外). 即, 训练是通过使有运量的小批量梯度下降优化多项式逻辑回归目标来进行的. batch size 设置为 256. 动量为 0.9. 通过权重衰减 (L2 惩罚乘数设置为 5e-4), 对前两个全链接层设置 0.5 的 dropout. 学习率最初设置为 10-2, 然后在验证集精度停止提高时除低 10 倍. 总体而言, 学习率降低了 3 倍, 并且在 370K 次迭代 (74 epoch) 之后, 停止了学习.
尽管与 (Krizhevsky et al.,2012) 相比, 我们的网络数量更多, 网络深度更大, 但由于:

1. 深度更大且卷积核较小而产生的隐式正则化.
2. 某些层的预初始化.

我们推测, 网络收敛所需的 epoch 更少 .


网络权重的初始化很重要, 因为糟糕的初始化会由于深度网络中的梯度不稳定而使学习停滞. 为了解决这个问题, 我们从训练配置 A 开始. 该配置足够浅, 可以通过随机初始化进行训练. 然后, 当训练更深的体系结构时, 我们用网络 A 的层初始化前四个卷积层和最后三个全连接层 (中间层是随机初始化的). 我们没有降低预初始化层的学习速度, 而是允许它们在学习过程中进行更改. 对于随机初始化, 我们**从 0 均值, 1e-2 的标准差的正态分布中取样**. bias 偏置设置为 0. 值得注意的是, 在论文提交后, 我们发现可以通过使用 Glorot & Bengio (2010) 的随机初始化程序在不进行预训练的情况下初始化权重.

为了获得固定尺寸的 224×224 的 ConvNet 输入图像, 我们从重新缩放的训练图像中随机裁剪出输入图像 (每个 SGD 迭代每个图像一个裁剪). 为了进一步增加训练集, 还对图像进行随机水平翻转, 随机 RGB 颜色转换. 训练图像重新缩放将在下面说明.

**训练图像大小**: 令 S 是图像各向同性缩放后的最短边, 然后从图中裁剪出 ConvNet 输入图像. 当裁剪尺寸固定为 224×224 时, S 可以取任何大于 224 的值: 当 S==224 时, 则将跨越图像的最短边进行裁剪, 对于 S 远大于 224, 则裁剪后的图像只包含图像的一小部分, 其中包含一个小物体或一个物体的部分. 我们考虑两种设置训练尺寸 S 的方法. 首先固定 S, 它对应于单尺度训练 (请注意, 裁剪图像内容仍可以表示多尺度图像统计信息). 在我们的实验中, 我们评估了在两个固定比例下训练的模型: S=256 (在现有技术中已被广泛使用), S=384. 给定 ConvNet 配置, 我们首先使用 S=256 训练网络. 为了加快 S=384 网络的训练, 它使用 S=256 预先训练的权重进行了初始化, 我们使用了较小的初始学习率 1e-3.

设置 S 的第二种方法是多尺度训练, 其中通过从某个范围 [Smin, Smax] (我们使用 Smin=256 和 Smax=512) 中随机抽样 S 来分别缩放每个训练图像的大小. 由于图像中的对象可以具有不同的大小, 因此在训练过程中考虑这一点是有益的. 当使用单个模型在很广泛的范围做物体识别时, 这也可以看作是通过尺度抖动增强训练集. 出于速度原因, 我们通过对具有相同配置的单尺度模型的所有层进行微调来训练多尺度模型, 并使用固定 S=384 进行了预先训练.

#### 3.2 测试

在测试时, 使用已训练的 ConvNet 和输入图像, 通过以下方法进行分类. 首先, 各向同性地将其缩放到预定义的最小图像边, 表示为 Q (我们也将其称为测试比例). 注意, Q 不必须与训练尺度 S 相同. 然后, 以类似于 (Sermanet et al.,2014) 的方式将网络密集地应用到重新缩放的测试图像上. 即, 首先将完全连接的层转换为卷积层 (第一个 FC 层转换为 7×7 积层, 最后两个 FC 层转换为 1×1 卷积层). 然后将所得的全卷积网络应用于整个 (未裁剪) 图像. 结果是一个类别评分图, 其中通道数等于类别数, 并且空间分辨率取决于输入图像的大小. 最后, 为了获得图像的类别分数的固定大小矢量, 对类别分数图进行空间平均. 我们还通过水平翻转图像来增强测试集. 对原始图像和翻转图像的soft-max 类后验进行平均, 以获得图像的最终分数.

由于将全卷积网络应用于整个图像, 因此无需在测试时对多个裁剪框进行采样, 它要求网络对每一个裁剪区重新计算, 所以效率较低. 同时, 如 Szegedy 等人所做的那样, 使用大量裁剪区. (2014年) 可以提高精度, 因为与全卷积网络相比, 它可以对输入图像进行更好的采样. 同样, 由于不同的卷积边界条件, 多裁剪评估与密集评估是互补的: 将ConvNet 应用于一个裁剪区时, 卷积特征图会填充零, 而在密集评估的情况下, 同样的区域则采用图像相邻区域的部分填充 (由于卷积和空间池化), 这大大增加了整个网络的感受野, 因此捕获了更多上下文. 但我们认为, 多裁剪所需要的更多的训练时间并不能证明其精度上的潜在准确性提高, 但作为参考, 我们还使用每个尺度 50 个裁剪, 三个尺度 150 个裁剪, 其相当于 Szegedy 等人使用 144 种 4 种规模的裁剪.



#### 3.3 实现细节
我们的实现源自可公开使用的 C++ Caffe 工具箱 (Jia, 2013年) (于2013年12月推出), 但包含许多重大修改, 使我们能够对安装在单个系统中的多个 GPU 上进行多尺度的和全尺雨的训练和评估, 多 GPU 训练利用了数据并行性, 并且通过将每批训练图像分为几批 GPU 来执行, 并在每个GPU上并行处理. 计算完 GPU 批次梯度后, 将其平均以获得整个批次的梯度. 梯度计算在 GPU 之间是同步的, 因此结果与在单个 GPU 上进行训练时完全相同. 虽然最近提出了更复杂的方法来加速 ConvNet 训练 (Krizhevsky, 2014), 该方法针对网络的不同层采用了模型和数据并行性, 但我们发现, 从概念上讲, 简单得多的方案已经可以在 4-GPU 的系统上提供 3.75 倍于单 GPU 的系统. 在配备有四个NVIDIA Titan Black GPU 的系统上, 根据架构的不同, 训练单个网络要花费 2-3 周.